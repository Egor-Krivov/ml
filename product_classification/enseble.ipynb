{
 "metadata": {
  "name": "",
  "signature": "sha256:18102586b165c71b11e73bde27b1d023e7a5163ad1559f320f18be07eac193c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib\n",
      "import seaborn as sns\n",
      "from sklearn import feature_extraction, preprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('train.csv')\n",
      "data = data.drop(['id'], axis=1)\n",
      "\n",
      "data_for_X = data.drop(['target'], axis=1)\n",
      "\n",
      "y = data.target.values\n",
      "lbl_enc = preprocessing.LabelEncoder()\n",
      "y = lbl_enc.fit_transform(y)\n",
      "data.target = y\n",
      "\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>feat_1</th>\n",
        "      <th>feat_2</th>\n",
        "      <th>feat_3</th>\n",
        "      <th>feat_4</th>\n",
        "      <th>feat_5</th>\n",
        "      <th>feat_6</th>\n",
        "      <th>feat_7</th>\n",
        "      <th>feat_8</th>\n",
        "      <th>feat_9</th>\n",
        "      <th>feat_10</th>\n",
        "      <th>...</th>\n",
        "      <th>feat_85</th>\n",
        "      <th>feat_86</th>\n",
        "      <th>feat_87</th>\n",
        "      <th>feat_88</th>\n",
        "      <th>feat_89</th>\n",
        "      <th>feat_90</th>\n",
        "      <th>feat_91</th>\n",
        "      <th>feat_92</th>\n",
        "      <th>feat_93</th>\n",
        "      <th>target</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 94 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
        "0       1       0       0       0       0       0       0       0       0   \n",
        "1       0       0       0       0       0       0       0       1       0   \n",
        "2       0       0       0       0       0       0       0       1       0   \n",
        "3       1       0       0       1       6       1       5       0       0   \n",
        "4       0       0       0       0       0       0       0       0       0   \n",
        "\n",
        "   feat_10   ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
        "0        0   ...           1        0        0        0        0        0   \n",
        "1        0   ...           0        0        0        0        0        0   \n",
        "2        0   ...           0        0        0        0        0        0   \n",
        "3        1   ...           0        1        2        0        0        0   \n",
        "4        0   ...           1        0        0        0        0        1   \n",
        "\n",
        "   feat_91  feat_92  feat_93  target  \n",
        "0        0        0        0       0  \n",
        "1        0        0        0       0  \n",
        "2        0        0        0       0  \n",
        "3        0        0        0       0  \n",
        "4        0        0        0       0  \n",
        "\n",
        "[5 rows x 94 columns]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "research = data.copy()\n",
      "raw_X = data_for_X.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.preprocessing import scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def engineer_features(data_for_X, add_zeroes=False):\n",
      "    raw_X = data_for_X.values\n",
      "    \n",
      "    tfidf = TfidfTransformer()\n",
      "    X_base = tfidf.fit_transform(raw_X[:,:93]).toarray() #original 93 features\n",
      "    \n",
      "    X_engineered = np.empty((raw_X.shape[0], 3))\n",
      "    X_engineered[:, 0] = np.sum(raw_X, axis=1)\n",
      "    X_engineered[:, 1] = np.sum(raw_X ** 0.5, axis=1)\n",
      "    X_engineered[:, 2] = np.sum(raw_X == 0, axis=1)\n",
      "    X_engineered = scale(X_engineered)\n",
      "    \n",
      "    if add_zeroes:\n",
      "        X_zeroes = np.array(raw_X[:,:93] == 0, dtype=float)\n",
      "        X_engineered = np.hstack((X_engineered, X_zeroes))\n",
      "    \n",
      "    X = np.hstack((X_base, X_engineered))\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = engineer_features(data_for_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit\n",
      "from sklearn.metrics import log_loss\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "\n",
      "#cv = StratifiedKFold(y, 4, shuffle=True, random_state=0)\n",
      "cv = ShuffleSplit(X.shape[0], n_iter=1, test_size=0.25, random_state=0)\n",
      "train, test = next(iter(cv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(61878, 96)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "log_clf = LogisticRegression(C=20.0)\n",
      "X_fe = engineer_features(data_for_X, add_zeroes=True)\n",
      "log_clf.fit(X_fe[train], y[train])\n",
      "\n",
      "log_loss(y[test], log_clf.predict_proba(X_fe[test]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0.60665950709848626"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_clf = RandomForestClassifier(criterion='gini', max_depth=32, max_features=34, n_estimators=256, random_state=0)\n",
      "rf_clf.fit(X[train], y[train])\n",
      "\n",
      "log_loss(y[test], rf_clf.predict_proba(X[test]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 216,
       "text": [
        "0.56673739027398673"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "\n",
      "class meta_classifier():\n",
      "    def __init__():\n",
      "        self.log_clf = LogisticRegression(C=20.0)\n",
      "        self.rf_clf = RandomForestClassifier(criterion='gini', max_depth=32, max_features=34, n_estimators=128, random_state=0)\n",
      "        self.erf_clf = ExtraTreesClassifier(criterion='gini', max_depth=40, max_features=40, n_estimators=128, random_state=0)\n",
      "        self.calc = lambda a, b, c: (a + b + c) / 3\n",
      "        #self.gb_clf = GradientBoostingClassifier(lea)\n",
      "    def fit(X, y):\n",
      "        X_fe_zeroes = engineer_features(data_for_X, add_zeroes=True)\n",
      "        self.log_clf.fit(X_fe, y)\n",
      "        self.rf_clf.fit(X, y)\n",
      "        self.erf_clf.fix(X, y)\n",
      "    def predict_proba(X):\n",
      "        predictions = []\n",
      "        X_engineer_features(data_for_X, add_zeroes=True)\n",
      "        predictions.append(self.log_clf.predict_proba(X_fe))\n",
      "        return self.calc(self.log_clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "erf_clf = ExtraTreesClassifier(criterion='gini', max_depth=40, max_features=80, n_estimators=256, random_state=0)\n",
      "erf_clf.fit(X[train], y[train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 217,
       "text": [
        "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
        "           max_depth=40, max_features=80, max_leaf_nodes=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=256, n_jobs=1,\n",
        "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gb_clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=8, max_features=70, n_estimators=64)\n",
      "gb_clf.fit(X[train], y[train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=8, max_features=70, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=64,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(X):\n",
      "    for i in range(X.shape[0]):\n",
      "        X[i] /= np.sum(X[i])\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = []\n",
      "predictions.append(log_clf.predict_proba(X_fe[test]))\n",
      "predictions.append(rf_clf.predict_proba(X[test]))\n",
      "predictions.append(erf_clf.predict_proba(X[test]))\n",
      "predictions.append(gb_clf.predict_proba(X[test]))\n",
      "[log_loss(y[test], p) for p in predictions]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 235,
       "text": [
        "[0.60665950709848626,\n",
        " 0.56673739027398673,\n",
        " 0.53024859470657304,\n",
        " 0.53765919371188142]"
       ]
      }
     ],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shift_prediction(X):\n",
      "    def increase_in_prediction(i):\n",
      "        base = log_loss(y[test][:7500], normalize(X[:7500]))\n",
      "        return log_loss(y[test][:7500], normalize(X[:7500] + i)) - base\n",
      "    r = minimize(increase_in_prediction, [0.000001])\n",
      "    print(r.x)\n",
      "    X[:] = normalize(X[:] + r.x[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[shift_prediction(p) for p in predictions]\n",
      "print([log_loss(y[test][:7500], p[:7500]) for p in predictions])\n",
      "[log_loss(y[test][7500:], p[7500:]) for p in predictions]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.61510227e-05]\n",
        "[  5.02918335e-05]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[  7.32437310e-05]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[-0.00017139]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0.59728157175438334, 0.55942709515422895, 0.52426860173554601, 0.52968573654559115]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 234,
       "text": [
        "[0.61530885737971597,\n",
        " 0.56776700569633531,\n",
        " 0.52984733962125008,\n",
        " 0.54443758341172599]"
       ]
      }
     ],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_erf = erf_clf.predict_proba(X[test])\n",
      "values = np.logspace(-5, -3, 30)\n",
      "base = log_loss(y[test], normalize(prediction_erf))\n",
      "l = []\n",
      "for i in values:\n",
      "    l.append(log_loss(y[test], normalize(prediction_erf + i)) - base)\n",
      "plt.plot(values, l)\n",
      "plt.xscale('log')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_prob_log = np.max(prediction_log, axis=1)\n",
      "max_prob_rf = np.max(prediction_rf, axis=1)\n",
      "max_prob_log.sort()\n",
      "max_prob_rf.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_gb = gb_clf.predict_proba(X[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(max_prob_log)\n",
      "plt.plot(max_prob_rf)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loss(x):\n",
      "    group_prediction = np.zeros(predictions[0].shape)\n",
      "    for i, prediction in enumerate(predictions):\n",
      "        group_prediction += x[i] * prediction ** x[i + 1]\n",
      "    group_prediction = normalize(group_prediction)\n",
      "    return log_loss(y[test][:7500], group_prediction[:7500])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import minimize\n",
      "\n",
      "bounds = [(0.0, 10.0)] * 8\n",
      "#constraints = dict(type='ineq', fun=lambda x: (x[0] > 0.0) and (x[1] > 0.0) and (x[2]>0.0) and (x[3] > 0.0) and (x[4] > 0.0) and (x[5] > 0.0) and (x[6] > 0.0))\n",
      "result = minimize(loss, [0.01, 1.0, 0.01, 1.0, 1.0, 1.0, 1.0, 1.0], tol=1e-3, bounds=bounds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 214,
       "text": [
        "       x: array([ 0.27223554,  0.81641626,  4.0700448 ,  1.48081963,  1.17745985,\n",
        "        1.        ,  1.        ,  1.        ])\n",
        "     fun: 0.48636172157240704\n",
        " success: True\n",
        "  status: 0\n",
        " message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
        "     nit: 4\n",
        "     jac: array([ -5.32801026e-03,  -3.15597548e-04,  -5.98243677e-05,\n",
        "        -6.99967861e-04,  -2.50616750e-03,   0.00000000e+00,\n",
        "         0.00000000e+00,   0.00000000e+00])\n",
        "    nfev: 50"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = result.x\n",
      "group_prediction = np.zeros(predictions[0].shape)\n",
      "for i, prediction in enumerate(predictions):\n",
      "    group_prediction += x[i] * prediction ** x[i + 1]\n",
      "group_prediction = normalize(group_prediction)\n",
      "log_loss(y[test][7500:], group_prediction[7500:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 215,
       "text": [
        "0.49711130703941409"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "composite_prediction = np.hstack(predictions)\n",
      "composite_prediction.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 237,
       "text": [
        "(15470, 36)"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = []\n",
      "space = np.linspace(0.0001, 100.0, 20)\n",
      "for i in space:\n",
      "    ensemble_log_reg = LogisticRegression(C=i)\n",
      "    ensemble_log_reg.fit(composite_prediction[:7500], y[test][:7500])\n",
      "    l.append(log_loss(y[test][7500:], ensemble_log_reg.predict_proba(composite_prediction[7500:])))\n",
      "    \n",
      "plt.plot(space, l)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_loss(y[test][7500:], ensemble_log_reg.predict_proba(composite_prediction[7500:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 245,
       "text": [
        "0.56958555036990477"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "composite_classes = y[test]\n",
      "\n",
      "\n",
      "param_grid = {\n",
      "    'max_features':[4],\n",
      "    'max_depth':[14, 16],\n",
      "    'n_estimators':[256]\n",
      "}\n",
      "cv = ShuffleSplit(composite_prediction.shape[0], n_iter=1, test_size=0.5, random_state=1)\n",
      "\n",
      "clf = ExtraTreesClassifier()\n",
      "clf = GridSearchCV(clf, param_grid, scoring='log_loss', n_jobs=1)\n",
      "clf.fit(composite_prediction, composite_classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 278,
       "text": [
        "GridSearchCV(cv=None, error_score='raise',\n",
        "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
        "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [256], 'max_depth': [14, 16], 'max_features': [4]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring='log_loss', verbose=0)"
       ]
      }
     ],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 279,
       "text": [
        "[mean: -0.50368, std: 0.00470, params: {'n_estimators': 256, 'max_depth': 14, 'max_features': 4},\n",
        " mean: -0.50259, std: 0.00674, params: {'n_estimators': 256, 'max_depth': 16, 'max_features': 4}]"
       ]
      }
     ],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_loss(y[test][7500:], clf.predict_proba(composite_prediction[7500:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 260,
       "text": [
        "0.54777487566899297"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}